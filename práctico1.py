# -*- coding: utf-8 -*-
"""Práctico1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13de1w7E-qRne2ePUikrWMawPqkY1n2iB
"""

#Ejercicio 1
#Inicializamos las bibliotecas:
import pandas as pd
import seaborn as sns 
import numpy as np
import matplotlib.pyplot as plt

#abro un dataset y lo visualizo 
datas = pd.read_csv('https://raw.githubusercontent.com/manlio99/Materia-de-aprendizaje/master/4_DataWrangling/data/casos_covid_bahia.csv', header=0, sep=",")
print(datas.shape)
print(datas)

#Calculamos variables estadísticas básicas (media, desvío estandar, etc
  print(datas.describe())

#Graficamos el histograma y boxplot de distintas variables del dataset para poder hacer un análisis visual de la información contenida:

graf1=datas['confirmados'].hist()
plt.show(graf1)
graf2=sns.boxplot(y=datas['confirmados'])
plt.show(graf2)
graf3=datas['confirmados'].plot()
plt.show(graf3)

#Respuestas sobre el primer dataset:
#Las observaciones del dataset son acumulativas. Para tener un mejor analisis habría que obtener el conteo diario de las distintas variables/atributos.
#No se puede determinar directamente si la distribución de las observaciones es normal o Gaussiana debido al caracter acumulativo, y aún obteniendo el conteo diario no cumplen con algunas condiciones básicas como pueden ser:
#Ser simétricas respecto a la media.
#Tener el máximo en la media.
#Crece hasta la media y decrece a partir de ella

#Repuestas sobre el segundo dataset:



#abro el segundo dataset y lo visualizo 
datas1 = pd.read_csv('https://raw.githubusercontent.com/manlio99/Materia-de-aprendizaje/master/4_DataWrangling/data/camas_covid_bahia.csv', header=0, sep=",")
print(datas1.shape)
print(datas1)

#Calculamos variables estadísticas básicas (media, desvío estandar, etc
  print(datas1.describe())

graf10=datas1['total_camas_hospitales'].hist()
plt.show(graf10)
graf20=sns.boxplot(y=datas1['total_camas_hospitales'])
plt.show(graf20)
graf30=datas1['total_camas_hospitales'].plot()
plt.show(graf30)

graf1=datas1['camas_sospechosos_covid'].hist()
plt.show(graf1)
graf2=sns.boxplot(y=datas1['camas_sospechosos_covid'])
plt.show(graf2)
graf3=datas1['camas_sospechosos_covid'].plot()
plt.show(graf3)

graf4=datas1['respiradores_ocupados'].hist()
plt.show(graf4)
graf5=sns.boxplot(y=datas1['respiradores_ocupados'])
plt.show(graf5)
graf6=datas1['respiradores_ocupados'].plot()
plt.show(graf3)

#Hacemos el mismo análisis exploratorio con el segundo dataset, en este caso la toma de datos/observaciones no son acumulativas.

#En el caso de la variable "total_camas_hospitales" las observaciones se mantienen relativamente constantes en el tiempo, aunque ciertas observaciones figuran en cero.
#Las variables "camas_sospechosos_covid" y "respiradores_ocupados" son las que presentan una distribución más parecida a la normal o Gaussiana.

#Generar un dataset similar al de la pág. 12 de este apunte (dos conjuntos Gaussianos con diferente media y DS, N=50 c/u, uno con etiqueta A y otro con etiqueta B).

#Importamos las herramientas de la biblioteca de scikit learn para generar nuestra curva ROC.

from sklearn import metrics
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

#Creamos 2 conjuntos de datos que sigan una distribución Gaussiana con 50 muestras cada uno, distinta media y desvío.
med1,des1,size1=(20,5,50) #media, desvío y n del primer muestreo
d1=np.random.normal(med1,des1,size1)
a=pd.DataFrame((d1),columns=['var'])
a['clase']=0
print(a.shape)
graf1=plt.hist(d1)
plt.show(graf1)

med2,des2,size2=(15,2,50) #media, desvío y n del segundo muestreo
d2=np.random.normal(med2,des2,size2)
b=pd.DataFrame((d2),columns=['var'])
b['clase']=1
print(b.shape)
graf2=plt.hist(d2)
plt.show(graf2)

dataf=pd.concat([a,b])
dataf['var'].describe()

# sets de entrenamiento y testeo para usar luego en la clasificación.

#Generamos nuestros sets de entrenamiento y testeo para usar luego en la clasificación.
print(dataf)

dat = dataf.drop(columns='clase')
clase = dataf['clase']

train_dat, test_dat, train_clase, test_clase=train_test_split(dat, clase, test_size=0.5)
print(train_dat.shape)
print(train_clase.shape)
print(test_clase.shape)

#Generamos una curva de clasificación aleatoria.
aleat = [0 for _ in range(len(test_clase))]
print(aleat)

#Aplicamos un método de clasificación mediante regresión logística a nuestro dataset
model=LogisticRegression(solver='lbfgs')
model.fit(train_dat,train_clase)

#Predecimos las probabilidades de las dos clases.
log_reg = model.predict_proba(test_dat)
print(log_reg.shape)
#print(log_reg)

#Me quedo solo con los resultados positivos.
log_reg_pos = log_reg[:,1]
print(log_reg_pos.shape)

#Calculamos los resultados del AUC (área bajo la curva) para la regresión logística y la clasificación aleatoria:
aleat_auc = roc_auc_score(test_clase, aleat)
log_reg_auc = roc_auc_score(test_clase,log_reg_pos)
print('Aleatoria: ROC AUC=',(aleat_auc))
print('Logística: ROC AUC=',(log_reg_auc))

#Calculamos la curva ROC y alguno de los parámetros de calidad del clasificador:
aleat_fpr, aleat_tpr, _ = roc_curve(test_clase, aleat)
log_reg_fpr, log_reg_tpr, _ = roc_curve(test_clase, log_reg_pos)

#Graficamos la curva ROC correspondiente al ejemplo desarrollado
plt.plot(aleat_fpr, aleat_tpr, label="Aleatoria")
plt.plot(log_reg_fpr, log_reg_tpr, label="Regresión Logística")
plt.xlabel("False Positive Rate") #Agregamos el nombre al eje X
plt.ylabel("True Positive Rate")  #Agregamos el nombre al eje Y
plt.legend()  #Agregamos las referencias
plt.show()  #Mostramos el gráfico completo

#Evaluamos la performance de nuestro modelo de clasificación a través de distintos parámetros.
pred = model.predict(test_dat)
acc = metrics.accuracy_score(test_clase,pred)
prec = metrics.precision_score(test_clase,pred)
f_mes = metrics.f1_score(test_clase,pred)

print('La exactitud del modelo fue:',acc)
print('La precisión del modelo fue:',prec)
print('El valor de f-measure fue:',f_mes)

#Hacemos la matriz de confusión para visualizar los resultados del clasificador, para ello primero debemos importar la función correspondiente de scikit learn.

from sklearn.metrics import confusion_matrix
print(confusion_matrix)

cf_mtx = metrics.confusion_matrix(test_clase,pred)   #calculo de la matriz
print(cf_mtx)

clases=[0,1]    #Graficamos la matriz de confusión
fig,ax = plt.subplots()
referencias = np.arange(len(clases))
plt.xticks(referencias, clases)
plt.yticks(referencias, clases)

sns.heatmap(pd.DataFrame(cf_mtx), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusión', y=1.1)
plt.ylabel('Clase Real')
plt.xlabel('Clase Predicha')